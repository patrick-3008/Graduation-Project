{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "371a9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrickn\\Jupyter_notebooks\\Graduation\\kokoro\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\Patrickn\\Jupyter_notebooks\\Graduation\\kokoro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aee9b1",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c9623738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kokoro import KPipeline, KModel\n",
    "from IPython.display import display, Audio\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import AutoProcessor, SpeechT5HifiGan\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torchaudio import load as load_audio\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b1dbd60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "pipeline = KPipeline(lang_code='a')\n",
    "text = 'Hello, My name is Patrick'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4dc64d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Hello, My name is Patrick həlˈO, mˌI nˈAm ɪz pˈætɹɪk\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(text, voice='am_puck')\n",
    "for i, (gs, ps, audio) in enumerate(generator):\n",
    "    print(i, gs, ps)\n",
    "    #display(Audio(data=audio, rate=24000, autoplay=i==0))\n",
    "    sf.write(f'{i}.wav', audio, 24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9a86d",
   "metadata": {},
   "source": [
    "# Pre-proccess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0c0f5e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D6x81u_1.mp3</td>\n",
       "      <td>خليني ابدا الفيديو ده وانا بقول ان من</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6f5WmH_2.mp3</td>\n",
       "      <td>ااا ملاحظتي الشخصيه استنتجت ان الستات ما</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abSOwC_3.mp3</td>\n",
       "      <td>بقاش عندها دم</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qqiArB_4.mp3</td>\n",
       "      <td>وان الستات بداوا يستغلوا الرجاله وان</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afzWCf_5.mp3</td>\n",
       "      <td>الستات دول</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     audio_file                                      text gender\n",
       "0  D6x81u_1.mp3     خليني ابدا الفيديو ده وانا بقول ان من   male\n",
       "1  6f5WmH_2.mp3  ااا ملاحظتي الشخصيه استنتجت ان الستات ما   male\n",
       "2  abSOwC_3.mp3                             بقاش عندها دم   male\n",
       "3  qqiArB_4.mp3      وان الستات بداوا يستغلوا الرجاله وان   male\n",
       "4  afzWCf_5.mp3                                الستات دول   male"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"C:/Users/Patrickn/Jupyter_notebooks/Graduation/Dataset/index.csv\"  # Replace with the actual path\n",
    "audio_folder = \"C:/Users/Patrickn/Jupyter_notebooks/Graduation/Dataset/sample\"    # Replace with the actual path\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b461cde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrickn\\Jupyter_notebooks\\Graduation\\Dataset\\sample\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/Patrickn/Jupyter_notebooks/Graduation/Dataset/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7bcb6f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = os.listdir(\"C:/Users/Patrickn/Jupyter_notebooks/Graduation/Dataset/sample\")\n",
    "\n",
    "filenames = [f for f in os.listdir() if os.path.isfile(f)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1cb21c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrickn\\Jupyter_notebooks\\Graduation\\kokoro\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/Patrickn/Jupyter_notebooks/Graduation/kokoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ce1cf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the 'filename' column matches one in the list\n",
    "filtered_df = df[df['audio_file'].isin(filenames)]\n",
    "\n",
    "# Save the filtered CSV (optional)\n",
    "filtered_df.to_csv(\"filtered_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bb9b9859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04HTH0_314.mp3</td>\n",
       "      <td>أحيانًا، لو لا قدّر الله، حصل اصطدام،</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00x68G_697.mp3</td>\n",
       "      <td>وكده عشان انت بتحط في مواقف انك تنزل</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04m0cQ_852.mp3</td>\n",
       "      <td>ومشينا</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>027PYP_1114.mp3</td>\n",
       "      <td>كل حاجه مره بقى عربي سول</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06UK7q_276.mp3</td>\n",
       "      <td>فمثلًا، كان الحُكام والإقطاعيين من عاداتهم</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        audio_file                                        text gender\n",
       "0   04HTH0_314.mp3       أحيانًا، لو لا قدّر الله، حصل اصطدام،   male\n",
       "1   00x68G_697.mp3        وكده عشان انت بتحط في مواقف انك تنزل   male\n",
       "2   04m0cQ_852.mp3                                      ومشينا   male\n",
       "3  027PYP_1114.mp3                    كل حاجه مره بقى عربي سول   male\n",
       "4   06UK7q_276.mp3  فمثلًا، كان الحُكام والإقطاعيين من عاداتهم   male"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"C:/Users/Patrickn/Jupyter_notebooks/Graduation/Dataset/filtered_dataset.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "25d7cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your CSV has columns 'filename' and 'text'\n",
    "df['audio_file'] = df['audio_file'].apply(lambda x: os.path.join(audio_folder, x))\n",
    "#dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "279e2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio_file\", Audio(sampling_rate=16000)) # Assuming a target sampling rate of 16000 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d3a97ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_file = row['audio_file']\n",
    "        text = row['text']\n",
    "        audio_tensor = load_audio(audio_file)[0]\n",
    "\n",
    "        # Pad or truncate audio to the target length\n",
    "        if audio_tensor.size(1) > self.target_length:\n",
    "            audio_tensor = audio_tensor[:, :self.target_length]\n",
    "        else:\n",
    "            padding = self.target_length - audio_tensor.size(1)\n",
    "            audio_tensor = torch.nn.functional.pad(audio_tensor, (0, padding))\n",
    "\n",
    "        return {\n",
    "            'audio_file': audio_tensor,\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "class SequentialDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_file = row['audio_file']\n",
    "        text = row['text']\n",
    "        audio_tensor = load_audio(audio_file)[0]\n",
    "\n",
    "        # Pad or truncate audio to the target length\n",
    "        if audio_tensor.size(1) > self.target_length:\n",
    "            audio_tensor = audio_tensor[:, :self.target_length]\n",
    "        else:\n",
    "            padding = self.target_length - audio_tensor.size(1)\n",
    "            audio_tensor = torch.nn.functional.pad(audio_tensor, (0, padding))\n",
    "\n",
    "        # Convert text from string to tensor of Unicode codepoints\n",
    "        text_tensor = torch.tensor([ord(c) for c in text], dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            'audio_file': audio_tensor,\n",
    "            'text': text_tensor\n",
    "        }\n",
    "\n",
    "# Convert the DataFrame to a sequential dataset\n",
    "sequential_dataset = SequentialDataset(df, target_length=target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d7900350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    audio_list = [item['audio_file'] for item in batch]\n",
    "    text_list = []\n",
    "    for item in batch:\n",
    "        text = item['text']\n",
    "        if isinstance(text, str):\n",
    "            text_tensor = torch.tensor([ord(c) for c in text], dtype=torch.float32)\n",
    "        elif not torch.is_tensor(text):\n",
    "            # Convert lists (or other iterables) to tensor\n",
    "            text_tensor = torch.tensor(text, dtype=torch.float32)\n",
    "        else:\n",
    "            text_tensor = text\n",
    "        text_list.append(text_tensor)\n",
    "\n",
    "    padded_audio = pad_sequence(audio_list, batch_first=True)\n",
    "    padded_text = pad_sequence(text_list, batch_first=True)\n",
    "    return {\n",
    "        'audio_file': padded_audio.to(device),\n",
    "        'text': padded_text.to(device)\n",
    "    }\n",
    "\n",
    "# Create DataLoader using the custom collate function\n",
    "data_loader = DataLoader(sequential_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cc508",
   "metadata": {},
   "source": [
    "# FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5a4530fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KModel(\n",
       "  (bert): CustomAlbert(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(178, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertSdpaAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=2048, bias=True)\n",
       "              (ffn_output): Linear(in_features=2048, out_features=768, bias=True)\n",
       "              (activation): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (bert_encoder): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (predictor): ProsodyPredictor(\n",
       "    (text_encoder): DurationEncoder(\n",
       "      (lstms): ModuleList(\n",
       "        (0): LSTM(640, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "        (1): AdaLayerNorm(\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (2): LSTM(640, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "        (3): AdaLayerNorm(\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (4): LSTM(640, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "        (5): AdaLayerNorm(\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(640, 256, batch_first=True, bidirectional=True)\n",
       "    (duration_proj): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=512, out_features=50, bias=True)\n",
       "    )\n",
       "    (shared): LSTM(640, 256, batch_first=True, bidirectional=True)\n",
       "    (F0): ModuleList(\n",
       "      (0): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pool): Identity()\n",
       "      )\n",
       "      (1): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1x1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pool): ConvTranspose1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,), groups=512)\n",
       "      )\n",
       "      (2): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pool): Identity()\n",
       "      )\n",
       "    )\n",
       "    (N): ModuleList(\n",
       "      (0): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pool): Identity()\n",
       "      )\n",
       "      (1): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1x1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pool): ConvTranspose1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,), groups=512)\n",
       "      )\n",
       "      (2): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pool): Identity()\n",
       "      )\n",
       "    )\n",
       "    (F0_proj): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
       "    (N_proj): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (text_encoder): TextEncoder(\n",
       "    (embedding): Embedding(178, 512)\n",
       "    (cnn): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (1): LayerNorm()\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (encode): AdainResBlk1d(\n",
       "      (actv): LeakyReLU(negative_slope=0.2)\n",
       "      (upsample): UpSample1d()\n",
       "      (conv1): Conv1d(514, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): AdaIN1d(\n",
       "        (norm): InstanceNorm1d(514, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (fc): Linear(in_features=128, out_features=1028, bias=True)\n",
       "      )\n",
       "      (norm2): AdaIN1d(\n",
       "        (norm): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (fc): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      )\n",
       "      (conv1x1): Conv1d(514, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (pool): Identity()\n",
       "    )\n",
       "    (decode): ModuleList(\n",
       "      (0-2): 3 x AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(1090, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(1090, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=2180, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        )\n",
       "        (conv1x1): Conv1d(1090, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (pool): Identity()\n",
       "      )\n",
       "      (3): AdainResBlk1d(\n",
       "        (actv): LeakyReLU(negative_slope=0.2)\n",
       "        (upsample): UpSample1d()\n",
       "        (conv1): Conv1d(1090, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(1090, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=2180, bias=True)\n",
       "        )\n",
       "        (norm2): AdaIN1d(\n",
       "          (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (fc): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (conv1x1): Conv1d(1090, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (pool): ConvTranspose1d(1090, 1090, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,), groups=1090)\n",
       "      )\n",
       "    )\n",
       "    (F0_conv): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (N_conv): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (asr_res): Sequential(\n",
       "      (0): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (generator): Generator(\n",
       "      (m_source): SourceModuleHnNSF(\n",
       "        (l_sin_gen): SineGen()\n",
       "        (l_linear): Linear(in_features=9, out_features=1, bias=True)\n",
       "        (l_tanh): Tanh()\n",
       "      )\n",
       "      (f0_upsamp): Upsample(scale_factor=300.0, mode='nearest')\n",
       "      (noise_convs): ModuleList(\n",
       "        (0): Conv1d(22, 256, kernel_size=(12,), stride=(6,), padding=(3,))\n",
       "        (1): Conv1d(22, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (noise_res): ModuleList(\n",
       "        (0): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "        )\n",
       "        (1): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ConvTranspose1d(512, 256, kernel_size=(20,), stride=(10,), padding=(5,))\n",
       "        (1): ConvTranspose1d(256, 128, kernel_size=(12,), stride=(6,), padding=(3,))\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "        )\n",
       "        (1): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "        )\n",
       "        (2): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x256x1]\n",
       "          )\n",
       "        )\n",
       "        (3): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "        )\n",
       "        (4): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "        )\n",
       "        (5): AdaINResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (adain1): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (adain2): ModuleList(\n",
       "            (0-2): 3 x AdaIN1d(\n",
       "              (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (alpha1): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "          (alpha2): ParameterList(\n",
       "              (0): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (1): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "              (2): Parameter containing: [torch.float32 of size 1x128x1]\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(128, 22, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (reflection_pad): ReflectionPad1d((1, 0))\n",
       "      (stft): TorchSTFT()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = KModel(repo_id='hexgrad/Kokoro-82M')\n",
    "\n",
    "# Move model to the appropriate device (GPU is highly recommended for finetuning)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "773703e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unknown variables\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "target_length = 16000\n",
    "total_loss = 0\n",
    "\n",
    "# Define loss functions\n",
    "criterion_duration = torch.nn.CrossEntropyLoss()\n",
    "criterion_mel = torch.nn.MSELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4a8861c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 1/1000\n",
      "Processing sample 2/1000\n",
      "Processing sample 3/1000\n",
      "Processing sample 4/1000\n",
      "Processing sample 5/1000\n",
      "Processing sample 6/1000\n",
      "Processing sample 7/1000\n",
      "Processing sample 8/1000\n",
      "Processing sample 9/1000\n",
      "Processing sample 10/1000\n",
      "Processing sample 11/1000\n",
      "Processing sample 12/1000\n",
      "Processing sample 13/1000\n",
      "Processing sample 14/1000\n",
      "Processing sample 15/1000\n",
      "Processing sample 16/1000\n",
      "Processing sample 17/1000\n",
      "Processing sample 18/1000\n",
      "Processing sample 19/1000\n",
      "Processing sample 20/1000\n",
      "Processing sample 21/1000\n",
      "Processing sample 22/1000\n",
      "Processing sample 23/1000\n",
      "Processing sample 24/1000\n",
      "Processing sample 25/1000\n",
      "Processing sample 26/1000\n",
      "Processing sample 27/1000\n",
      "Processing sample 28/1000\n",
      "Processing sample 29/1000\n",
      "Processing sample 30/1000\n",
      "Processing sample 31/1000\n",
      "Processing sample 32/1000\n",
      "Processing sample 33/1000\n",
      "Processing sample 34/1000\n",
      "Processing sample 35/1000\n",
      "Processing sample 36/1000\n",
      "Processing sample 37/1000\n",
      "Processing sample 38/1000\n",
      "Processing sample 39/1000\n",
      "Processing sample 40/1000\n",
      "Processing sample 41/1000\n",
      "Processing sample 42/1000\n",
      "Processing sample 43/1000\n",
      "Processing sample 44/1000\n",
      "Processing sample 45/1000\n",
      "Processing sample 46/1000\n",
      "Processing sample 47/1000\n",
      "Processing sample 48/1000\n",
      "Processing sample 49/1000\n",
      "Processing sample 50/1000\n",
      "Processing sample 51/1000\n",
      "Processing sample 52/1000\n",
      "Processing sample 53/1000\n",
      "Processing sample 54/1000\n",
      "Processing sample 55/1000\n",
      "Processing sample 56/1000\n",
      "Processing sample 57/1000\n",
      "Processing sample 58/1000\n",
      "Processing sample 59/1000\n",
      "Processing sample 60/1000\n",
      "Processing sample 61/1000\n",
      "Processing sample 62/1000\n",
      "Processing sample 63/1000\n",
      "Processing sample 64/1000\n",
      "Processing sample 65/1000\n",
      "Processing sample 66/1000\n",
      "Processing sample 67/1000\n",
      "Processing sample 68/1000\n",
      "Processing sample 69/1000\n",
      "Processing sample 70/1000\n",
      "Processing sample 71/1000\n",
      "Processing sample 72/1000\n",
      "Processing sample 73/1000\n",
      "Processing sample 74/1000\n",
      "Processing sample 75/1000\n",
      "Processing sample 76/1000\n",
      "Processing sample 77/1000\n",
      "Processing sample 78/1000\n",
      "Processing sample 79/1000\n",
      "Processing sample 80/1000\n",
      "Processing sample 81/1000\n",
      "Processing sample 82/1000\n",
      "Processing sample 83/1000\n",
      "Processing sample 84/1000\n",
      "Processing sample 85/1000\n",
      "Processing sample 86/1000\n",
      "Processing sample 87/1000\n",
      "Processing sample 88/1000\n",
      "Processing sample 89/1000\n",
      "Processing sample 90/1000\n",
      "Processing sample 91/1000\n",
      "Processing sample 92/1000\n",
      "Processing sample 93/1000\n",
      "Processing sample 94/1000\n",
      "Processing sample 95/1000\n",
      "Processing sample 96/1000\n",
      "Processing sample 97/1000\n",
      "Processing sample 98/1000\n",
      "Processing sample 99/1000\n",
      "Processing sample 100/1000\n",
      "Processing sample 101/1000\n",
      "Processing sample 102/1000\n",
      "Processing sample 103/1000\n",
      "Processing sample 104/1000\n",
      "Processing sample 105/1000\n",
      "Processing sample 106/1000\n",
      "Processing sample 107/1000\n",
      "Processing sample 108/1000\n",
      "Processing sample 109/1000\n",
      "Processing sample 110/1000\n",
      "Processing sample 111/1000\n",
      "Processing sample 112/1000\n",
      "Processing sample 113/1000\n",
      "Processing sample 114/1000\n",
      "Processing sample 115/1000\n",
      "Processing sample 116/1000\n",
      "Processing sample 117/1000\n",
      "Processing sample 118/1000\n",
      "Processing sample 119/1000\n",
      "Processing sample 120/1000\n",
      "Processing sample 121/1000\n",
      "Processing sample 122/1000\n",
      "Processing sample 123/1000\n",
      "Processing sample 124/1000\n",
      "Processing sample 125/1000\n",
      "Processing sample 126/1000\n",
      "Processing sample 127/1000\n",
      "Processing sample 128/1000\n",
      "Processing sample 129/1000\n",
      "Processing sample 130/1000\n",
      "Processing sample 131/1000\n",
      "Processing sample 132/1000\n",
      "Processing sample 133/1000\n",
      "Processing sample 134/1000\n",
      "Processing sample 135/1000\n",
      "Processing sample 136/1000\n",
      "Processing sample 137/1000\n",
      "Processing sample 138/1000\n",
      "Processing sample 139/1000\n",
      "Processing sample 140/1000\n",
      "Processing sample 141/1000\n",
      "Processing sample 142/1000\n",
      "Processing sample 143/1000\n",
      "Processing sample 144/1000\n",
      "Processing sample 145/1000\n",
      "Processing sample 146/1000\n",
      "Processing sample 147/1000\n",
      "Processing sample 148/1000\n",
      "Processing sample 149/1000\n",
      "Processing sample 150/1000\n",
      "Processing sample 151/1000\n",
      "Processing sample 152/1000\n",
      "Processing sample 153/1000\n",
      "Processing sample 154/1000\n",
      "Processing sample 155/1000\n",
      "Processing sample 156/1000\n",
      "Processing sample 157/1000\n",
      "Processing sample 158/1000\n",
      "Processing sample 159/1000\n",
      "Processing sample 160/1000\n",
      "Processing sample 161/1000\n",
      "Processing sample 162/1000\n",
      "Processing sample 163/1000\n",
      "Processing sample 164/1000\n",
      "Processing sample 165/1000\n",
      "Processing sample 166/1000\n",
      "Processing sample 167/1000\n",
      "Processing sample 168/1000\n",
      "Processing sample 169/1000\n",
      "Processing sample 170/1000\n",
      "Processing sample 171/1000\n",
      "Processing sample 172/1000\n",
      "Processing sample 173/1000\n",
      "Processing sample 174/1000\n",
      "Processing sample 175/1000\n",
      "Processing sample 176/1000\n",
      "Processing sample 177/1000\n",
      "Processing sample 178/1000\n",
      "Processing sample 179/1000\n",
      "Processing sample 180/1000\n",
      "Processing sample 181/1000\n",
      "Processing sample 182/1000\n",
      "Processing sample 183/1000\n",
      "Processing sample 184/1000\n",
      "Processing sample 185/1000\n",
      "Processing sample 186/1000\n",
      "Processing sample 187/1000\n",
      "Processing sample 188/1000\n",
      "Processing sample 189/1000\n",
      "Processing sample 190/1000\n",
      "Processing sample 191/1000\n",
      "Processing sample 192/1000\n",
      "Processing sample 193/1000\n",
      "Processing sample 194/1000\n",
      "Processing sample 195/1000\n",
      "Processing sample 196/1000\n",
      "Processing sample 197/1000\n",
      "Processing sample 198/1000\n",
      "Processing sample 199/1000\n",
      "Processing sample 200/1000\n",
      "Processing sample 201/1000\n",
      "Processing sample 202/1000\n",
      "Processing sample 203/1000\n",
      "Processing sample 204/1000\n",
      "Processing sample 205/1000\n",
      "Processing sample 206/1000\n",
      "Processing sample 207/1000\n",
      "Processing sample 208/1000\n",
      "Processing sample 209/1000\n",
      "Processing sample 210/1000\n",
      "Processing sample 211/1000\n",
      "Processing sample 212/1000\n",
      "Processing sample 213/1000\n",
      "Processing sample 214/1000\n",
      "Processing sample 215/1000\n",
      "Processing sample 216/1000\n",
      "Processing sample 217/1000\n",
      "Processing sample 218/1000\n",
      "Processing sample 219/1000\n",
      "Processing sample 220/1000\n",
      "Processing sample 221/1000\n",
      "Processing sample 222/1000\n",
      "Processing sample 223/1000\n",
      "Processing sample 224/1000\n",
      "Processing sample 225/1000\n",
      "Processing sample 226/1000\n",
      "Processing sample 227/1000\n",
      "Processing sample 228/1000\n",
      "Processing sample 229/1000\n",
      "Processing sample 230/1000\n",
      "Processing sample 231/1000\n",
      "Processing sample 232/1000\n",
      "Processing sample 233/1000\n",
      "Processing sample 234/1000\n",
      "Processing sample 235/1000\n",
      "Processing sample 236/1000\n",
      "Processing sample 237/1000\n",
      "Processing sample 238/1000\n",
      "Processing sample 239/1000\n",
      "Processing sample 240/1000\n",
      "Processing sample 241/1000\n",
      "Processing sample 242/1000\n",
      "Processing sample 243/1000\n",
      "Processing sample 244/1000\n",
      "Processing sample 245/1000\n",
      "Processing sample 246/1000\n",
      "Processing sample 247/1000\n",
      "Processing sample 248/1000\n",
      "Processing sample 249/1000\n",
      "Processing sample 250/1000\n",
      "Processing sample 251/1000\n",
      "Processing sample 252/1000\n",
      "Processing sample 253/1000\n",
      "Processing sample 254/1000\n",
      "Processing sample 255/1000\n",
      "Processing sample 256/1000\n",
      "Processing sample 257/1000\n",
      "Processing sample 258/1000\n",
      "Processing sample 259/1000\n",
      "Processing sample 260/1000\n",
      "Processing sample 261/1000\n",
      "Processing sample 262/1000\n",
      "Processing sample 263/1000\n",
      "Processing sample 264/1000\n",
      "Processing sample 265/1000\n",
      "Processing sample 266/1000\n",
      "Processing sample 267/1000\n",
      "Processing sample 268/1000\n",
      "Processing sample 269/1000\n",
      "Processing sample 270/1000\n",
      "Processing sample 271/1000\n",
      "Processing sample 272/1000\n",
      "Processing sample 273/1000\n",
      "Processing sample 274/1000\n",
      "Processing sample 275/1000\n",
      "Processing sample 276/1000\n",
      "Processing sample 277/1000\n",
      "Processing sample 278/1000\n",
      "Processing sample 279/1000\n",
      "Processing sample 280/1000\n",
      "Processing sample 281/1000\n",
      "Processing sample 282/1000\n",
      "Processing sample 283/1000\n",
      "Processing sample 284/1000\n",
      "Processing sample 285/1000\n",
      "Processing sample 286/1000\n",
      "Processing sample 287/1000\n",
      "Processing sample 288/1000\n",
      "Processing sample 289/1000\n",
      "Processing sample 290/1000\n",
      "Processing sample 291/1000\n",
      "Processing sample 292/1000\n",
      "Processing sample 293/1000\n",
      "Processing sample 294/1000\n",
      "Processing sample 295/1000\n",
      "Processing sample 296/1000\n",
      "Processing sample 297/1000\n",
      "Processing sample 298/1000\n",
      "Processing sample 299/1000\n",
      "Processing sample 300/1000\n",
      "Processing sample 301/1000\n",
      "Processing sample 302/1000\n",
      "Processing sample 303/1000\n",
      "Processing sample 304/1000\n",
      "Processing sample 305/1000\n",
      "Processing sample 306/1000\n",
      "Processing sample 307/1000\n",
      "Processing sample 308/1000\n",
      "Processing sample 309/1000\n",
      "Processing sample 310/1000\n",
      "Processing sample 311/1000\n",
      "Processing sample 312/1000\n",
      "Processing sample 313/1000\n",
      "Processing sample 314/1000\n",
      "Processing sample 315/1000\n",
      "Processing sample 316/1000\n",
      "Processing sample 317/1000\n",
      "Processing sample 318/1000\n",
      "Processing sample 319/1000\n",
      "Processing sample 320/1000\n",
      "Processing sample 321/1000\n",
      "Processing sample 322/1000\n",
      "Processing sample 323/1000\n",
      "Processing sample 324/1000\n",
      "Processing sample 325/1000\n",
      "Processing sample 326/1000\n",
      "Processing sample 327/1000\n",
      "Processing sample 328/1000\n",
      "Processing sample 329/1000\n",
      "Processing sample 330/1000\n",
      "Processing sample 331/1000\n",
      "Processing sample 332/1000\n",
      "Processing sample 333/1000\n",
      "Processing sample 334/1000\n",
      "Processing sample 335/1000\n",
      "Processing sample 336/1000\n",
      "Processing sample 337/1000\n",
      "Processing sample 338/1000\n",
      "Processing sample 339/1000\n",
      "Processing sample 340/1000\n",
      "Processing sample 341/1000\n",
      "Processing sample 342/1000\n",
      "Processing sample 343/1000\n",
      "Processing sample 344/1000\n",
      "Processing sample 345/1000\n",
      "Processing sample 346/1000\n",
      "Processing sample 347/1000\n",
      "Processing sample 348/1000\n",
      "Processing sample 349/1000\n",
      "Processing sample 350/1000\n",
      "Processing sample 351/1000\n",
      "Processing sample 352/1000\n",
      "Processing sample 353/1000\n",
      "Processing sample 354/1000\n",
      "Processing sample 355/1000\n",
      "Processing sample 356/1000\n",
      "Processing sample 357/1000\n",
      "Processing sample 358/1000\n",
      "Processing sample 359/1000\n",
      "Processing sample 360/1000\n",
      "Processing sample 361/1000\n",
      "Processing sample 362/1000\n",
      "Processing sample 363/1000\n",
      "Processing sample 364/1000\n",
      "Processing sample 365/1000\n",
      "Processing sample 366/1000\n",
      "Processing sample 367/1000\n",
      "Processing sample 368/1000\n",
      "Processing sample 369/1000\n",
      "Processing sample 370/1000\n",
      "Processing sample 371/1000\n",
      "Processing sample 372/1000\n",
      "Processing sample 373/1000\n",
      "Processing sample 374/1000\n",
      "Processing sample 375/1000\n",
      "Processing sample 376/1000\n",
      "Processing sample 377/1000\n",
      "Processing sample 378/1000\n",
      "Processing sample 379/1000\n",
      "Processing sample 380/1000\n",
      "Processing sample 381/1000\n",
      "Processing sample 382/1000\n",
      "Processing sample 383/1000\n",
      "Processing sample 384/1000\n",
      "Processing sample 385/1000\n",
      "Processing sample 386/1000\n",
      "Processing sample 387/1000\n",
      "Processing sample 388/1000\n",
      "Processing sample 389/1000\n",
      "Processing sample 390/1000\n",
      "Processing sample 391/1000\n",
      "Processing sample 392/1000\n",
      "Processing sample 393/1000\n",
      "Processing sample 394/1000\n",
      "Processing sample 395/1000\n",
      "Processing sample 396/1000\n",
      "Processing sample 397/1000\n",
      "Processing sample 398/1000\n",
      "Processing sample 399/1000\n",
      "Processing sample 400/1000\n",
      "Processing sample 401/1000\n",
      "Processing sample 402/1000\n",
      "Processing sample 403/1000\n",
      "Processing sample 404/1000\n",
      "Processing sample 405/1000\n",
      "Processing sample 406/1000\n",
      "Processing sample 407/1000\n",
      "Processing sample 408/1000\n",
      "Processing sample 409/1000\n",
      "Processing sample 410/1000\n",
      "Processing sample 411/1000\n",
      "Processing sample 412/1000\n",
      "Processing sample 413/1000\n",
      "Processing sample 414/1000\n",
      "Processing sample 415/1000\n",
      "Processing sample 416/1000\n",
      "Processing sample 417/1000\n",
      "Processing sample 418/1000\n",
      "Processing sample 419/1000\n",
      "Processing sample 420/1000\n",
      "Processing sample 421/1000\n",
      "Processing sample 422/1000\n",
      "Processing sample 423/1000\n",
      "Processing sample 424/1000\n",
      "Processing sample 425/1000\n",
      "Processing sample 426/1000\n",
      "Processing sample 427/1000\n",
      "Processing sample 428/1000\n",
      "Processing sample 429/1000\n",
      "Processing sample 430/1000\n",
      "Processing sample 431/1000\n",
      "Processing sample 432/1000\n",
      "Processing sample 433/1000\n",
      "Processing sample 434/1000\n",
      "Processing sample 435/1000\n",
      "Processing sample 436/1000\n",
      "Processing sample 437/1000\n",
      "Processing sample 438/1000\n",
      "Processing sample 439/1000\n",
      "Processing sample 440/1000\n",
      "Processing sample 441/1000\n",
      "Processing sample 442/1000\n",
      "Processing sample 443/1000\n",
      "Processing sample 444/1000\n",
      "Processing sample 445/1000\n",
      "Processing sample 446/1000\n",
      "Processing sample 447/1000\n",
      "Processing sample 448/1000\n",
      "Processing sample 449/1000\n",
      "Processing sample 450/1000\n",
      "Processing sample 451/1000\n",
      "Processing sample 452/1000\n",
      "Processing sample 453/1000\n",
      "Processing sample 454/1000\n",
      "Processing sample 455/1000\n",
      "Processing sample 456/1000\n",
      "Processing sample 457/1000\n",
      "Processing sample 458/1000\n",
      "Processing sample 459/1000\n",
      "Processing sample 460/1000\n",
      "Processing sample 461/1000\n",
      "Processing sample 462/1000\n",
      "Processing sample 463/1000\n",
      "Processing sample 464/1000\n",
      "Processing sample 465/1000\n",
      "Processing sample 466/1000\n",
      "Processing sample 467/1000\n",
      "Processing sample 468/1000\n",
      "Processing sample 469/1000\n",
      "Processing sample 470/1000\n",
      "Processing sample 471/1000\n",
      "Processing sample 472/1000\n",
      "Processing sample 473/1000\n",
      "Processing sample 474/1000\n",
      "Processing sample 475/1000\n",
      "Processing sample 476/1000\n",
      "Processing sample 477/1000\n",
      "Processing sample 478/1000\n",
      "Processing sample 479/1000\n",
      "Processing sample 480/1000\n",
      "Processing sample 481/1000\n",
      "Processing sample 482/1000\n",
      "Processing sample 483/1000\n",
      "Processing sample 484/1000\n",
      "Processing sample 485/1000\n",
      "Processing sample 486/1000\n",
      "Processing sample 487/1000\n",
      "Processing sample 488/1000\n",
      "Processing sample 489/1000\n",
      "Processing sample 490/1000\n",
      "Processing sample 491/1000\n",
      "Processing sample 492/1000\n",
      "Processing sample 493/1000\n",
      "Processing sample 494/1000\n",
      "Processing sample 495/1000\n",
      "Processing sample 496/1000\n",
      "Processing sample 497/1000\n",
      "Processing sample 498/1000\n",
      "Processing sample 499/1000\n",
      "Processing sample 500/1000\n",
      "Processing sample 501/1000\n",
      "Processing sample 502/1000\n",
      "Processing sample 503/1000\n",
      "Processing sample 504/1000\n",
      "Processing sample 505/1000\n",
      "Processing sample 506/1000\n",
      "Processing sample 507/1000\n",
      "Processing sample 508/1000\n",
      "Processing sample 509/1000\n",
      "Processing sample 510/1000\n",
      "Processing sample 511/1000\n",
      "Processing sample 512/1000\n",
      "Processing sample 513/1000\n",
      "Processing sample 514/1000\n",
      "Processing sample 515/1000\n",
      "Processing sample 516/1000\n",
      "Processing sample 517/1000\n",
      "Processing sample 518/1000\n",
      "Processing sample 519/1000\n",
      "Processing sample 520/1000\n",
      "Processing sample 521/1000\n",
      "Processing sample 522/1000\n",
      "Processing sample 523/1000\n",
      "Processing sample 524/1000\n",
      "Processing sample 525/1000\n",
      "Processing sample 526/1000\n",
      "Processing sample 527/1000\n",
      "Processing sample 528/1000\n",
      "Processing sample 529/1000\n",
      "Processing sample 530/1000\n",
      "Processing sample 531/1000\n",
      "Processing sample 532/1000\n",
      "Processing sample 533/1000\n",
      "Processing sample 534/1000\n",
      "Processing sample 535/1000\n",
      "Processing sample 536/1000\n",
      "Processing sample 537/1000\n",
      "Processing sample 538/1000\n",
      "Processing sample 539/1000\n",
      "Processing sample 540/1000\n",
      "Processing sample 541/1000\n",
      "Processing sample 542/1000\n",
      "Processing sample 543/1000\n",
      "Processing sample 544/1000\n",
      "Processing sample 545/1000\n",
      "Processing sample 546/1000\n",
      "Processing sample 547/1000\n",
      "Processing sample 548/1000\n",
      "Processing sample 549/1000\n",
      "Processing sample 550/1000\n",
      "Processing sample 551/1000\n",
      "Processing sample 552/1000\n",
      "Processing sample 553/1000\n",
      "Processing sample 554/1000\n",
      "Processing sample 555/1000\n",
      "Processing sample 556/1000\n",
      "Processing sample 557/1000\n",
      "Processing sample 558/1000\n",
      "Processing sample 559/1000\n",
      "Processing sample 560/1000\n",
      "Processing sample 561/1000\n",
      "Processing sample 562/1000\n",
      "Processing sample 563/1000\n",
      "Processing sample 564/1000\n",
      "Processing sample 565/1000\n",
      "Processing sample 566/1000\n",
      "Processing sample 567/1000\n",
      "Processing sample 568/1000\n",
      "Processing sample 569/1000\n",
      "Processing sample 570/1000\n",
      "Processing sample 571/1000\n",
      "Processing sample 572/1000\n",
      "Processing sample 573/1000\n",
      "Processing sample 574/1000\n",
      "Processing sample 575/1000\n",
      "Processing sample 576/1000\n",
      "Processing sample 577/1000\n",
      "Processing sample 578/1000\n",
      "Processing sample 579/1000\n",
      "Processing sample 580/1000\n",
      "Processing sample 581/1000\n",
      "Processing sample 582/1000\n",
      "Processing sample 583/1000\n",
      "Processing sample 584/1000\n",
      "Processing sample 585/1000\n",
      "Processing sample 586/1000\n",
      "Processing sample 587/1000\n",
      "Processing sample 588/1000\n",
      "Processing sample 589/1000\n",
      "Processing sample 590/1000\n",
      "Processing sample 591/1000\n",
      "Processing sample 592/1000\n",
      "Processing sample 593/1000\n",
      "Processing sample 594/1000\n",
      "Processing sample 595/1000\n",
      "Processing sample 596/1000\n",
      "Processing sample 597/1000\n",
      "Processing sample 598/1000\n",
      "Processing sample 599/1000\n",
      "Processing sample 600/1000\n",
      "Processing sample 601/1000\n",
      "Processing sample 602/1000\n",
      "Processing sample 603/1000\n",
      "Processing sample 604/1000\n",
      "Processing sample 605/1000\n",
      "Processing sample 606/1000\n",
      "Processing sample 607/1000\n",
      "Processing sample 608/1000\n",
      "Processing sample 609/1000\n",
      "Processing sample 610/1000\n",
      "Processing sample 611/1000\n",
      "Processing sample 612/1000\n",
      "Processing sample 613/1000\n",
      "Processing sample 614/1000\n",
      "Processing sample 615/1000\n",
      "Processing sample 616/1000\n",
      "Processing sample 617/1000\n",
      "Processing sample 618/1000\n",
      "Processing sample 619/1000\n",
      "Processing sample 620/1000\n",
      "Processing sample 621/1000\n",
      "Processing sample 622/1000\n",
      "Processing sample 623/1000\n",
      "Processing sample 624/1000\n",
      "Processing sample 625/1000\n",
      "Processing sample 626/1000\n",
      "Processing sample 627/1000\n",
      "Processing sample 628/1000\n",
      "Processing sample 629/1000\n",
      "Processing sample 630/1000\n",
      "Processing sample 631/1000\n",
      "Processing sample 632/1000\n",
      "Processing sample 633/1000\n",
      "Processing sample 634/1000\n",
      "Processing sample 635/1000\n",
      "Processing sample 636/1000\n",
      "Processing sample 637/1000\n",
      "Processing sample 638/1000\n",
      "Processing sample 639/1000\n",
      "Processing sample 640/1000\n",
      "Processing sample 641/1000\n",
      "Processing sample 642/1000\n",
      "Processing sample 643/1000\n",
      "Processing sample 644/1000\n",
      "Processing sample 645/1000\n",
      "Processing sample 646/1000\n",
      "Processing sample 647/1000\n",
      "Processing sample 648/1000\n",
      "Processing sample 649/1000\n",
      "Processing sample 650/1000\n",
      "Processing sample 651/1000\n",
      "Processing sample 652/1000\n",
      "Processing sample 653/1000\n",
      "Processing sample 654/1000\n",
      "Processing sample 655/1000\n",
      "Processing sample 656/1000\n",
      "Processing sample 657/1000\n",
      "Processing sample 658/1000\n",
      "Processing sample 659/1000\n",
      "Processing sample 660/1000\n",
      "Processing sample 661/1000\n",
      "Processing sample 662/1000\n",
      "Processing sample 663/1000\n",
      "Processing sample 664/1000\n",
      "Processing sample 665/1000\n",
      "Processing sample 666/1000\n",
      "Processing sample 667/1000\n",
      "Processing sample 668/1000\n",
      "Processing sample 669/1000\n",
      "Processing sample 670/1000\n",
      "Processing sample 671/1000\n",
      "Processing sample 672/1000\n",
      "Processing sample 673/1000\n",
      "Processing sample 674/1000\n",
      "Processing sample 675/1000\n",
      "Processing sample 676/1000\n",
      "Processing sample 677/1000\n",
      "Processing sample 678/1000\n",
      "Processing sample 679/1000\n",
      "Processing sample 680/1000\n",
      "Processing sample 681/1000\n",
      "Processing sample 682/1000\n",
      "Processing sample 683/1000\n",
      "Processing sample 684/1000\n",
      "Processing sample 685/1000\n",
      "Processing sample 686/1000\n",
      "Processing sample 687/1000\n",
      "Processing sample 688/1000\n",
      "Processing sample 689/1000\n",
      "Processing sample 690/1000\n",
      "Processing sample 691/1000\n",
      "Processing sample 692/1000\n",
      "Processing sample 693/1000\n",
      "Processing sample 694/1000\n",
      "Processing sample 695/1000\n",
      "Processing sample 696/1000\n",
      "Processing sample 697/1000\n",
      "Processing sample 698/1000\n",
      "Processing sample 699/1000\n",
      "Processing sample 700/1000\n",
      "Processing sample 701/1000\n",
      "Processing sample 702/1000\n",
      "Processing sample 703/1000\n",
      "Processing sample 704/1000\n",
      "Processing sample 705/1000\n",
      "Processing sample 706/1000\n",
      "Processing sample 707/1000\n",
      "Processing sample 708/1000\n",
      "Processing sample 709/1000\n",
      "Processing sample 710/1000\n",
      "Processing sample 711/1000\n",
      "Processing sample 712/1000\n",
      "Processing sample 713/1000\n",
      "Processing sample 714/1000\n",
      "Processing sample 715/1000\n",
      "Processing sample 716/1000\n",
      "Processing sample 717/1000\n",
      "Processing sample 718/1000\n",
      "Processing sample 719/1000\n",
      "Processing sample 720/1000\n",
      "Processing sample 721/1000\n",
      "Processing sample 722/1000\n",
      "Processing sample 723/1000\n",
      "Processing sample 724/1000\n",
      "Processing sample 725/1000\n",
      "Processing sample 726/1000\n",
      "Processing sample 727/1000\n",
      "Processing sample 728/1000\n",
      "Processing sample 729/1000\n",
      "Processing sample 730/1000\n",
      "Processing sample 731/1000\n",
      "Processing sample 732/1000\n",
      "Processing sample 733/1000\n",
      "Processing sample 734/1000\n",
      "Processing sample 735/1000\n",
      "Processing sample 736/1000\n",
      "Processing sample 737/1000\n",
      "Processing sample 738/1000\n",
      "Processing sample 739/1000\n",
      "Processing sample 740/1000\n",
      "Processing sample 741/1000\n",
      "Processing sample 742/1000\n",
      "Processing sample 743/1000\n",
      "Processing sample 744/1000\n",
      "Processing sample 745/1000\n",
      "Processing sample 746/1000\n",
      "Processing sample 747/1000\n",
      "Processing sample 748/1000\n",
      "Processing sample 749/1000\n",
      "Processing sample 750/1000\n",
      "Processing sample 751/1000\n",
      "Processing sample 752/1000\n",
      "Processing sample 753/1000\n",
      "Processing sample 754/1000\n",
      "Processing sample 755/1000\n",
      "Processing sample 756/1000\n",
      "Processing sample 757/1000\n",
      "Processing sample 758/1000\n",
      "Processing sample 759/1000\n",
      "Processing sample 760/1000\n",
      "Processing sample 761/1000\n",
      "Processing sample 762/1000\n",
      "Processing sample 763/1000\n",
      "Processing sample 764/1000\n",
      "Processing sample 765/1000\n",
      "Processing sample 766/1000\n",
      "Processing sample 767/1000\n",
      "Processing sample 768/1000\n",
      "Processing sample 769/1000\n",
      "Processing sample 770/1000\n",
      "Processing sample 771/1000\n",
      "Processing sample 772/1000\n",
      "Processing sample 773/1000\n",
      "Processing sample 774/1000\n",
      "Processing sample 775/1000\n",
      "Processing sample 776/1000\n",
      "Processing sample 777/1000\n",
      "Processing sample 778/1000\n",
      "Processing sample 779/1000\n",
      "Processing sample 780/1000\n",
      "Processing sample 781/1000\n",
      "Processing sample 782/1000\n",
      "Processing sample 783/1000\n",
      "Processing sample 784/1000\n",
      "Processing sample 785/1000\n",
      "Processing sample 786/1000\n",
      "Processing sample 787/1000\n",
      "Processing sample 788/1000\n",
      "Processing sample 789/1000\n",
      "Processing sample 790/1000\n",
      "Processing sample 791/1000\n",
      "Processing sample 792/1000\n",
      "Processing sample 793/1000\n",
      "Processing sample 794/1000\n",
      "Processing sample 795/1000\n",
      "Processing sample 796/1000\n",
      "Processing sample 797/1000\n",
      "Processing sample 798/1000\n",
      "Processing sample 799/1000\n",
      "Processing sample 800/1000\n",
      "Processing sample 801/1000\n",
      "Processing sample 802/1000\n",
      "Processing sample 803/1000\n",
      "Processing sample 804/1000\n",
      "Processing sample 805/1000\n",
      "Processing sample 806/1000\n",
      "Processing sample 807/1000\n",
      "Processing sample 808/1000\n",
      "Processing sample 809/1000\n",
      "Processing sample 810/1000\n",
      "Processing sample 811/1000\n",
      "Processing sample 812/1000\n",
      "Processing sample 813/1000\n",
      "Processing sample 814/1000\n",
      "Processing sample 815/1000\n",
      "Processing sample 816/1000\n",
      "Processing sample 817/1000\n",
      "Processing sample 818/1000\n",
      "Processing sample 819/1000\n",
      "Processing sample 820/1000\n",
      "Processing sample 821/1000\n",
      "Processing sample 822/1000\n",
      "Processing sample 823/1000\n",
      "Processing sample 824/1000\n",
      "Processing sample 825/1000\n",
      "Processing sample 826/1000\n",
      "Processing sample 827/1000\n",
      "Processing sample 828/1000\n",
      "Processing sample 829/1000\n",
      "Processing sample 830/1000\n",
      "Processing sample 831/1000\n",
      "Processing sample 832/1000\n",
      "Processing sample 833/1000\n",
      "Processing sample 834/1000\n",
      "Processing sample 835/1000\n",
      "Processing sample 836/1000\n",
      "Processing sample 837/1000\n",
      "Processing sample 838/1000\n",
      "Processing sample 839/1000\n",
      "Processing sample 840/1000\n",
      "Processing sample 841/1000\n",
      "Processing sample 842/1000\n",
      "Processing sample 843/1000\n",
      "Processing sample 844/1000\n",
      "Processing sample 845/1000\n",
      "Processing sample 846/1000\n",
      "Processing sample 847/1000\n",
      "Processing sample 848/1000\n",
      "Processing sample 849/1000\n",
      "Processing sample 850/1000\n",
      "Processing sample 851/1000\n",
      "Processing sample 852/1000\n",
      "Processing sample 853/1000\n",
      "Processing sample 854/1000\n",
      "Processing sample 855/1000\n",
      "Processing sample 856/1000\n",
      "Processing sample 857/1000\n",
      "Processing sample 858/1000\n",
      "Processing sample 859/1000\n",
      "Processing sample 860/1000\n",
      "Processing sample 861/1000\n",
      "Processing sample 862/1000\n",
      "Processing sample 863/1000\n",
      "Processing sample 864/1000\n",
      "Processing sample 865/1000\n",
      "Processing sample 866/1000\n",
      "Processing sample 867/1000\n",
      "Processing sample 868/1000\n",
      "Processing sample 869/1000\n",
      "Processing sample 870/1000\n",
      "Processing sample 871/1000\n",
      "Processing sample 872/1000\n",
      "Processing sample 873/1000\n",
      "Processing sample 874/1000\n",
      "Processing sample 875/1000\n",
      "Processing sample 876/1000\n",
      "Processing sample 877/1000\n",
      "Processing sample 878/1000\n",
      "Processing sample 879/1000\n",
      "Processing sample 880/1000\n",
      "Processing sample 881/1000\n",
      "Processing sample 882/1000\n",
      "Processing sample 883/1000\n",
      "Processing sample 884/1000\n",
      "Processing sample 885/1000\n",
      "Processing sample 886/1000\n",
      "Processing sample 887/1000\n",
      "Processing sample 888/1000\n",
      "Processing sample 889/1000\n",
      "Processing sample 890/1000\n",
      "Processing sample 891/1000\n",
      "Processing sample 892/1000\n",
      "Processing sample 893/1000\n",
      "Processing sample 894/1000\n",
      "Processing sample 895/1000\n",
      "Processing sample 896/1000\n",
      "Processing sample 897/1000\n",
      "Processing sample 898/1000\n",
      "Processing sample 899/1000\n",
      "Processing sample 900/1000\n",
      "Processing sample 901/1000\n",
      "Processing sample 902/1000\n",
      "Processing sample 903/1000\n",
      "Processing sample 904/1000\n",
      "Processing sample 905/1000\n",
      "Processing sample 906/1000\n",
      "Processing sample 907/1000\n",
      "Processing sample 908/1000\n",
      "Processing sample 909/1000\n",
      "Processing sample 910/1000\n",
      "Processing sample 911/1000\n",
      "Processing sample 912/1000\n",
      "Processing sample 913/1000\n",
      "Processing sample 914/1000\n",
      "Processing sample 915/1000\n",
      "Processing sample 916/1000\n",
      "Processing sample 917/1000\n",
      "Processing sample 918/1000\n",
      "Processing sample 919/1000\n",
      "Processing sample 920/1000\n",
      "Processing sample 921/1000\n",
      "Processing sample 922/1000\n",
      "Processing sample 923/1000\n",
      "Processing sample 924/1000\n",
      "Processing sample 925/1000\n",
      "Processing sample 926/1000\n",
      "Processing sample 927/1000\n",
      "Processing sample 928/1000\n",
      "Processing sample 929/1000\n",
      "Processing sample 930/1000\n",
      "Processing sample 931/1000\n",
      "Processing sample 932/1000\n",
      "Processing sample 933/1000\n",
      "Processing sample 934/1000\n",
      "Processing sample 935/1000\n",
      "Processing sample 936/1000\n",
      "Processing sample 937/1000\n",
      "Processing sample 938/1000\n",
      "Processing sample 939/1000\n",
      "Processing sample 940/1000\n",
      "Processing sample 941/1000\n",
      "Processing sample 942/1000\n",
      "Processing sample 943/1000\n",
      "Processing sample 944/1000\n",
      "Processing sample 945/1000\n",
      "Processing sample 946/1000\n",
      "Processing sample 947/1000\n",
      "Processing sample 948/1000\n",
      "Processing sample 949/1000\n",
      "Processing sample 950/1000\n",
      "Processing sample 951/1000\n",
      "Processing sample 952/1000\n",
      "Processing sample 953/1000\n",
      "Processing sample 954/1000\n",
      "Processing sample 955/1000\n",
      "Processing sample 956/1000\n",
      "Processing sample 957/1000\n",
      "Processing sample 958/1000\n",
      "Processing sample 959/1000\n",
      "Processing sample 960/1000\n",
      "Processing sample 961/1000\n",
      "Processing sample 962/1000\n",
      "Processing sample 963/1000\n",
      "Processing sample 964/1000\n",
      "Processing sample 965/1000\n",
      "Processing sample 966/1000\n",
      "Processing sample 967/1000\n",
      "Processing sample 968/1000\n",
      "Processing sample 969/1000\n",
      "Processing sample 970/1000\n",
      "Processing sample 971/1000\n",
      "Processing sample 972/1000\n",
      "Processing sample 973/1000\n",
      "Processing sample 974/1000\n",
      "Processing sample 975/1000\n",
      "Processing sample 976/1000\n",
      "Processing sample 977/1000\n",
      "Processing sample 978/1000\n",
      "Processing sample 979/1000\n",
      "Processing sample 980/1000\n",
      "Processing sample 981/1000\n",
      "Processing sample 982/1000\n",
      "Processing sample 983/1000\n",
      "Processing sample 984/1000\n",
      "Processing sample 985/1000\n",
      "Processing sample 986/1000\n",
      "Processing sample 987/1000\n",
      "Processing sample 988/1000\n",
      "Processing sample 989/1000\n",
      "Processing sample 990/1000\n",
      "Processing sample 991/1000\n",
      "Processing sample 992/1000\n",
      "Processing sample 993/1000\n",
      "Processing sample 994/1000\n",
      "Processing sample 995/1000\n",
      "Processing sample 996/1000\n",
      "Processing sample 997/1000\n",
      "Processing sample 998/1000\n",
      "Processing sample 999/1000\n",
      "Processing sample 1000/1000\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dataset sequentially\n",
    "for idx in range(len(sequential_dataset)):\n",
    "    sample = sequential_dataset[idx]\n",
    "    audio_tensor = sample['audio_file']\n",
    "    text = sample['text']\n",
    "\n",
    "    # Process each sample individually\n",
    "    print(f\"Processing sample {idx + 1}/{len(sequential_dataset)}\")\n",
    "    # Add your processing logic here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "28143007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader and optimizer for Kokoro TTS\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "batch_size = 16\n",
    "data_loader = DataLoader(processed_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "criterion_duration = torch.nn.CrossEntropyLoss()\n",
    "criterion_mel = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "29c9eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (16) at non-singleton dimension 1.  Target sizes: [2, 1, -1].  Tensor sizes: [16, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     text_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpad_sequence(text_tensors, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss_duration \u001b[38;5;241m=\u001b[39m criterion_duration(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m], text_batch)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\kokoro\\model.py:133\u001b[0m, in \u001b[0;36mKModel.forward\u001b[1;34m(self, phonemes, ref_s, speed, return_output)\u001b[0m\n\u001b[0;32m    131\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39minput_ids, \u001b[38;5;241m0\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    132\u001b[0m ref_s \u001b[38;5;241m=\u001b[39m ref_s\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 133\u001b[0m audio, pred_dur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_with_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    135\u001b[0m pred_dur \u001b[38;5;241m=\u001b[39m pred_dur\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;28;01mif\u001b[39;00m pred_dur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\kokoro\\model.py:105\u001b[0m, in \u001b[0;36mKModel.forward_with_tokens\u001b[1;34m(self, input_ids, ref_s, speed)\u001b[0m\n\u001b[0;32m    103\u001b[0m d_en \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_encoder(bert_dur)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    104\u001b[0m s \u001b[38;5;241m=\u001b[39m ref_s[:, \u001b[38;5;241m128\u001b[39m:]\n\u001b[1;32m--> 105\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mlstm(d)\n\u001b[0;32m    107\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mduration_proj(x)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda\\envs\\kokoro\\lib\\site-packages\\kokoro\\modules.py:151\u001b[0m, in \u001b[0;36mDurationEncoder.forward\u001b[1;34m(self, x, style, text_lengths, m)\u001b[0m\n\u001b[0;32m    149\u001b[0m masks \u001b[38;5;241m=\u001b[39m m\n\u001b[0;32m    150\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 151\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, s], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    153\u001b[0m x\u001b[38;5;241m.\u001b[39mmasked_fill_(masks\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (16) at non-singleton dimension 1.  Target sizes: [2, 1, -1].  Tensor sizes: [16, 0]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop with dynamic padding for variable-length data\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        audio_batch = batch['audio_file']\n",
    "        text_batch = batch['text']\n",
    "        # Convert text_batch to tensor if it's a list of strings\n",
    "        if isinstance(text_batch, list):\n",
    "            text_tensors = [torch.tensor([ord(c) for c in txt], dtype=torch.float32) for txt in text_batch]\n",
    "            text_batch = torch.nn.utils.rnn.pad_sequence(text_tensors, batch_first=True).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(audio_batch, text_batch)\n",
    "\n",
    "        # Compute losses\n",
    "        loss_duration = criterion_duration(outputs['duration'], text_batch)\n",
    "        loss_mel = criterion_mel(outputs['mel'], audio_batch)\n",
    "        loss = loss_duration + loss_mel\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed with average loss: {running_loss / len(data_loader):.4f}\")\n",
    "\n",
    "print(\"Fine-tuning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22033bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kokoro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
