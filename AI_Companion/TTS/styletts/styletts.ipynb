{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b2e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrickn\\Jupyter_notebooks\\Graduation\\AI_Companion\\TTS\\styletts\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/styletts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b682cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/patrick-3008/StyleTTS2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2efeea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After initial mapping: ana asmj batrjk\n",
      "After rule 'aا': ana asmj batrjk\n",
      "After rule 'uو': ana asmj batrjk\n",
      "After rule 'iي': ana asmj batrjk\n",
      "After rule 'اى': ana asmj batrjk\n",
      "After rule '([btdðr z s ʃ sˤ dˤ tˤ ðˤ ʕ ʁ f q k l m n h w j ʔ]):': ana asmj batrjk\n",
      "After rule 'al([tθdðrzsʃsˤdˤtˤðˤln])': ana asmj batrjk\n",
      "After rule ':': ana asmj batrjk\n",
      "Input: انا اسمي باتريك\n",
      "Output: ana asmj batrjk\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# --- 1. Define Your Target Phoneme Set ---\n",
    "# This is a simplified set, close to IPA and what Espeak uses for Arabic.\n",
    "# You might need to expand this based on your specific needs.\n",
    "PHONEME_MAP = {\n",
    "    'ا': 'a',  # Alif - often carrier or part of long vowel/hamza\n",
    "    'ب': 'b',\n",
    "    'ت': 't',\n",
    "    'ث': 'θ',\n",
    "    'ج': 'dʒ', # Or 'g' depending on dialect (e.g., Egyptian)\n",
    "    'ح': 'ħ',\n",
    "    'خ': 'χ', # Or 'x'\n",
    "    'د': 'd',\n",
    "    'ذ': 'ð',\n",
    "    'ر': 'r',\n",
    "    'ز': 'z',\n",
    "    'س': 's',\n",
    "    'ش': 'ʃ',\n",
    "    'ص': 'sˤ', # Or 'S' for simplicity\n",
    "    'ض': 'dˤ', # Or 'D'\n",
    "    'ط': 'tˤ', # Or 'T'\n",
    "    'ظ': 'ðˤ', # Or 'DH'\n",
    "    'ع': 'ʕ',\n",
    "    'غ': 'ʁ', # Or 'ɣ' or 'g'\n",
    "    'ف': 'f',\n",
    "    'ق': 'q', # Or 'g' depending on dialect\n",
    "    'ك': 'k',\n",
    "    'ل': 'l',\n",
    "    'م': 'm',\n",
    "    'ن': 'n',\n",
    "    'ه': 'h',\n",
    "    'و': 'w',  # Wau - consonant or part of long vowel/diphthong\n",
    "    'ي': 'j',  # Ya - consonant or part of long vowel/diphthong\n",
    "    'ء': 'ʔ',  # Hamza\n",
    "    'آ': 'ʔaː', # Alif Madda\n",
    "    'ى': 'aː', # Alif Maqsura (often pronounced as long 'a')\n",
    "    'ة': 'h',  # Ta' Marbutah (simplified - often 't' in connected speech)\n",
    "\n",
    "    # --- Diacritics (Tashkeel) ---\n",
    "    'َ': 'a',  # Fatha\n",
    "    'ُ': 'u',  # Damma\n",
    "    'ِ': 'i',  # Kasra\n",
    "    'ْ': '',   # Sukun (indicates no vowel)\n",
    "    'ّ': ':',  # Shadda (indicates gemination - will be handled by a rule)\n",
    "    'ً': 'an', # Fathatan (Tanween Fath) - simplified, often dropped in pausal\n",
    "    'ٌ': 'un', # Dammatan (Tanween Damm) - simplified\n",
    "    'ٍ': 'in', # Kasratan (Tanween Kasr) - simplified\n",
    "\n",
    "    # --- Other characters to handle ---\n",
    "    ' ': ' ', # Space\n",
    "    # Add punctuation if needed and how to handle it (e.g., ignore, map to silence)\n",
    "}\n",
    "\n",
    "# --- 2. Define Phonological Rules ---\n",
    "# Rules will be applied sequentially. Order matters!\n",
    "# Each rule is a tuple: (pattern_to_find, replacement_phonemes)\n",
    "# We'll use regex for pattern matching.\n",
    "\n",
    "# Note: This is a very basic set of rules. A real system needs many more.\n",
    "# Handling unvocalized text requires inferring missing diacritics, which\n",
    "# is NOT covered by these simple rules.\n",
    "\n",
    "RULES = [\n",
    "    # Rule 1: Handle long vowels (short vowel + madd letter)\n",
    "    # Assumes short vowels are already mapped.\n",
    "    # e.g., a + ا -> aː\n",
    "    (r'aا', 'aː'),\n",
    "    (r'uو', 'uː'),\n",
    "    (r'iي', 'iː'),\n",
    "    # Handle Alif Maqsura as long 'a'\n",
    "    (r'اى', 'aː'), # Assuming Alif followed by Alif Maqsura results in long a\n",
    "\n",
    "    # Rule 2: Handle Shadda (gemination)\n",
    "    # Find a phoneme followed by the shadda marker ':' and duplicate the phoneme.\n",
    "    # This needs to be done carefully to avoid duplicating vowels or spaces.\n",
    "    # We'll look for a consonant phoneme before the ':'\n",
    "    # This regex is simplified; a real system needs more robust handling.\n",
    "    (r'([btdðr z s ʃ sˤ dˤ tˤ ðˤ ʕ ʁ f q k l m n h w j ʔ]):', r'\\1\\1'),\n",
    "\n",
    "\n",
    "    # Rule 3: Handle the definite article 'Al' (ال)\n",
    "    # This is a simplified rule for Sun letters assimilation.\n",
    "    # It assumes 'al' has already been mapped from 'ال'.\n",
    "    # Sun letters: ت ث د ذ ر ز س ش ص ض ط ظ ل ن\n",
    "    # We look for 'al' followed by a Sun letter's phoneme and assimilate.\n",
    "    # This rule assumes the Sun letter's phoneme is the next character.\n",
    "    # A more robust rule would check the *original* Arabic letter.\n",
    "    (r'al([tθdðrzsʃsˤdˤtˤðˤln])', r'a\\1\\1'), # al + SunLetter -> a + doubled SunLetter\n",
    "\n",
    "    # Rule 4: Clean up any remaining shadda markers if not processed (shouldn't happen with Rule 2)\n",
    "    (r':', ''),\n",
    "\n",
    "]\n",
    "\n",
    "# --- 3. Implement the G2P Function ---\n",
    "\n",
    "def arabic_g2p(text):\n",
    "    phonemes = []\n",
    "    for char in text:\n",
    "        if char in PHONEME_MAP:\n",
    "            phonemes.append(PHONEME_MAP[char])\n",
    "        else:\n",
    "            # Handle characters not in map (e.g., numbers, other symbols)\n",
    "            # You might want to raise an error or skip them.\n",
    "            print(f\"Warning: Character '{char}' not found in PHONEME_MAP. Skipping or mapping to itself.\")\n",
    "            phonemes.append(char) # Or '' to skip\n",
    "\n",
    "    # Join into a string to apply regex rules\n",
    "    phoneme_string = \"\".join(phonemes)\n",
    "    print(f\"After initial mapping: {phoneme_string}\") # Debugging\n",
    "\n",
    "    # Step 2: Apply Phonological Rules\n",
    "    processed_phonemes = phoneme_string\n",
    "    for pattern, replacement in RULES:\n",
    "        # Use re.sub to apply the rule globally\n",
    "        processed_phonemes = re.sub(pattern, replacement, processed_phonemes)\n",
    "        print(f\"After rule '{pattern}': {processed_phonemes}\") # Debugging\n",
    "\n",
    "    # Step 3: Final Cleanup (if needed)\n",
    "    # You might have leftover characters or need to format the output\n",
    "    # For example, removing extra spaces or adding stress markers if determined.\n",
    "    final_phonemes = processed_phonemes.strip() # Example: remove leading/trailing space\n",
    "\n",
    "    return final_phonemes\n",
    "\n",
    "# --- 4. Test the System ---\n",
    "\n",
    "unvocalized_phrase = \"انا اسمي باتريك\" # Ana ismi Patrick\n",
    "# This will also be challenging without diacritics.\n",
    "# Espeak output was ['ˈanaː ˈismiːj bˈaːtɹiːk ']\n",
    "# Our simple system will not produce this level of detail (stress, specific vowels)\n",
    "phonemic_output_phrase = arabic_g2p(unvocalized_phrase)\n",
    "print(f\"Input: {unvocalized_phrase}\")\n",
    "print(f\"Output: {phonemic_output_phrase}\")\n",
    "# Expected output (simplified and likely incorrect): ana asmy batryk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f387976",
   "metadata": {},
   "source": [
    "# PreProcess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fcb6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and Preparing Data Format 1 (Word Lexicon) ---\n",
      "Found 5 files to process.\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\egyptian_arabic_g2p_500.md\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\egyptian_arabic_g2p_500_additional.md\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\egyptian_arabic_g2p_new.md\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\egyptian_arabic_g2p_new_1000.md\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\egyptian_arabic_g2p_new_500.md\n",
      "\n",
      "--- Loading and Preparing Data Format 2 (Sentence Pairs) ---\n",
      "Found 15 files to process.\n",
      "Error decoding JSON data for format 2: Expecting property name enclosed in double quotes: line 1595 column 5 (char 90382)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_10.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_11.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_12.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_13.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_14.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_15.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_16.txt\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_2.txt\n",
      "Error decoding JSON data for format 2: Extra data: line 547 column 1 (char 32041)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_3.txt\n",
      "Error decoding JSON data for format 2: Extra data: line 547 column 1 (char 32041)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_4.txt\n",
      "Error decoding JSON data for format 2: Unterminated string starting at: line 1552 column 12 (char 90827)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_5.txt\n",
      "Error decoding JSON data for format 2: Unterminated string starting at: line 1631 column 13 (char 91547)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_6.txt\n",
      "Error decoding JSON data for format 2: Expecting value: line 2013 column 5 (char 117234)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_7.txt\n",
      "Error decoding JSON data for format 2: Unterminated string starting at: line 1679 column 13 (char 95302)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_8.txt\n",
      "Error decoding JSON data for format 2: Unterminated string starting at: line 672 column 12 (char 37473)\n",
      "Successfully processed: C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data\\g2p_9.txt\n",
      "\n",
      "==============================\n",
      "\n",
      "--- Data Loading Summary ---\n",
      "Total word-phoneme pairs loaded: 2776\n",
      "Total sentence pairs loaded: 1412\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "\n",
    "WORD_PHONEME_DIR = 'C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data'\n",
    "WORD_PHONEME_FILE_PATTERN = '*.md' # Adjust if your files have a different extension\n",
    "\n",
    "SENTENCE_DATA_DIR = 'C:/Users/Patrickn/Jupyter_notebooks/Graduation/AI_Companion/TTS/g2p_data'\n",
    "SENTENCE_DATA_FILE_PATTERN = '*.txt' # Adjust if your files have a different extension\n",
    "\n",
    "\n",
    "def parse_word_phoneme_pairs(raw_data):\n",
    "    word_phoneme_list = []\n",
    "    # Use io.StringIO to treat the string as a file\n",
    "    data_file = io.StringIO(raw_data.strip()) # strip() removes leading/trailing whitespace from the whole block\n",
    "\n",
    "    for line in data_file:\n",
    "        line = line.strip() # Remove leading/trailing whitespace from the line\n",
    "        if line: # Ensure the line is not empty\n",
    "            # Split the line by whitespace. Assumes the first token is the word\n",
    "            # and the rest is the phonemic transcription (joined by spaces if needed).\n",
    "            parts = line.split(maxsplit=1) # Split only on the first whitespace\n",
    "            if len(parts) == 2:\n",
    "                word = parts[0]\n",
    "                phonemes = parts[1].strip() # Ensure no extra whitespace around phonemes\n",
    "                # Basic validation: check if phonemes string is not empty after stripping\n",
    "                if phonemes:\n",
    "                     word_phoneme_list.append((word, phonemes))\n",
    "                else:\n",
    "                     print(f\"Warning: Skipping line with empty phonemes in format 1: '{line}'\")\n",
    "            else:\n",
    "                print(f\"Warning: Skipping malformed line in format 1: '{line}'\")\n",
    "\n",
    "    return word_phoneme_list\n",
    "\n",
    "def parse_sentence_data(raw_json_data):\n",
    "    try:\n",
    "        sentence_list = json.loads(raw_json_data)\n",
    "        # Basic validation to ensure the structure is as expected\n",
    "        if not isinstance(sentence_list, list):\n",
    "            print(\"Error: JSON data is not a list.\")\n",
    "            return []\n",
    "        valid_sentence_list = []\n",
    "        for item in sentence_list:\n",
    "            if isinstance(item, dict) and \"text\" in item and \"g2p\" in item:\n",
    "                 # Optional: Basic validation for non-empty strings\n",
    "                 if item[\"text\"] and item[\"g2p\"]:\n",
    "                    valid_sentence_list.append(item)\n",
    "                 else:\n",
    "                    print(f\"Warning: Skipping item with empty text or g2p in format 2: {item}\")\n",
    "            else:\n",
    "                print(f\"Warning: Skipping malformed item in format 2: {item}\")\n",
    "        return valid_sentence_list\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON data for format 2: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Data Loading and Preparation ---\n",
    "\n",
    "def load_data_from_files(directory=None, file_list=None, file_pattern='*', parser_func=None):\n",
    "    all_data = []\n",
    "    files_to_process = []\n",
    "\n",
    "    if file_list:\n",
    "        files_to_process = file_list\n",
    "    elif directory and os.path.isdir(directory):\n",
    "        files_to_process = glob.glob(os.path.join(directory, file_pattern))\n",
    "    else:\n",
    "        print(f\"Error: No valid directory or file list provided.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Found {len(files_to_process)} files to process.\")\n",
    "\n",
    "    for file_path in files_to_process:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                raw_data = f.read()\n",
    "                parsed_data = parser_func(raw_data)\n",
    "                all_data.extend(parsed_data)\n",
    "            print(f\"Successfully processed: {file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# --- Load and Prepare Datasets ---\n",
    "\n",
    "print(\"--- Loading and Preparing Data Format 1 (Word Lexicon) ---\")\n",
    "# Choose one option based on your configuration above (directory or file_list)\n",
    "# If using directory:\n",
    "all_word_phoneme_pairs = load_data_from_files(directory=WORD_PHONEME_DIR, file_pattern=WORD_PHONEME_FILE_PATTERN, parser_func=parse_word_phoneme_pairs)\n",
    "# If using file_list:\n",
    "# all_word_phoneme_pairs = load_data_from_files(file_list=WORD_PHONEME_FILES, parser_func=parse_word_phoneme_pairs)\n",
    "\n",
    "\n",
    "print(\"\\n--- Loading and Preparing Data Format 2 (Sentence Pairs) ---\")\n",
    "# Choose one option based on your configuration above (directory or file_list)\n",
    "# If using directory:\n",
    "all_sentence_pairs = load_data_from_files(directory=SENTENCE_DATA_DIR, file_pattern=SENTENCE_DATA_FILE_PATTERN, parser_func=parse_sentence_data)\n",
    "# If using file_list:\n",
    "# all_sentence_pairs = load_data_from_files(file_list=SENTENCE_DATA_FILES, parser_func=parse_sentence_data)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "print(\"--- Data Loading Summary ---\")\n",
    "print(f\"Total word-phoneme pairs loaded: {len(all_word_phoneme_pairs)}\")\n",
    "print(f\"Total sentence pairs loaded: {len(all_sentence_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeb2d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patrickn\\.conda\\envs\\tf_pyT\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for up to 50 epochs with patience of 5...\n",
      "Epoch 1/50 - Train Loss: 8.5031 - Val Loss: 8.2953\n",
      "Epoch 1/50 - Train Loss: 8.5031 - Val Loss: 8.2953\n",
      "Epoch 2/50 - Train Loss: 7.9112 - Val Loss: 8.2461\n",
      "Epoch 2/50 - Train Loss: 7.9112 - Val Loss: 8.2461\n",
      "Epoch 3/50 - Train Loss: 7.6787 - Val Loss: 8.1702\n",
      "Epoch 3/50 - Train Loss: 7.6787 - Val Loss: 8.1702\n",
      "Epoch 4/50 - Train Loss: 7.4267 - Val Loss: 8.1643\n",
      "Epoch 4/50 - Train Loss: 7.4267 - Val Loss: 8.1643\n",
      "Epoch 5/50 - Train Loss: 7.1657 - Val Loss: 8.1829\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "Epoch 5/50 - Train Loss: 7.1657 - Val Loss: 8.1829\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "Epoch 6/50 - Train Loss: 6.9068 - Val Loss: 8.1830\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "Epoch 6/50 - Train Loss: 6.9068 - Val Loss: 8.1830\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "Epoch 7/50 - Train Loss: 6.6806 - Val Loss: 8.1668\n",
      "Validation loss did not improve. Patience: 3/5\n",
      "Epoch 7/50 - Train Loss: 6.6806 - Val Loss: 8.1668\n",
      "Validation loss did not improve. Patience: 3/5\n",
      "Epoch 8/50 - Train Loss: 6.4703 - Val Loss: 8.1856\n",
      "Validation loss did not improve. Patience: 4/5\n",
      "Epoch 8/50 - Train Loss: 6.4703 - Val Loss: 8.1856\n",
      "Validation loss did not improve. Patience: 4/5\n",
      "Epoch 9/50 - Train Loss: 6.2739 - Val Loss: 8.1424\n",
      "Epoch 9/50 - Train Loss: 6.2739 - Val Loss: 8.1424\n",
      "Epoch 10/50 - Train Loss: 6.0871 - Val Loss: 8.1440\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "Epoch 10/50 - Train Loss: 6.0871 - Val Loss: 8.1440\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "Epoch 11/50 - Train Loss: 5.8968 - Val Loss: 8.1744\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "Epoch 11/50 - Train Loss: 5.8968 - Val Loss: 8.1744\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "Epoch 12/50 - Train Loss: 5.7316 - Val Loss: 8.1837\n",
      "Validation loss did not improve. Patience: 3/5\n",
      "Epoch 12/50 - Train Loss: 5.7316 - Val Loss: 8.1837\n",
      "Validation loss did not improve. Patience: 3/5\n",
      "Epoch 13/50 - Train Loss: 5.5623 - Val Loss: 8.1948\n",
      "Validation loss did not improve. Patience: 4/5\n",
      "Epoch 13/50 - Train Loss: 5.5623 - Val Loss: 8.1948\n",
      "Validation loss did not improve. Patience: 4/5\n",
      "Epoch 14/50 - Train Loss: 5.4110 - Val Loss: 8.1840\n",
      "Validation loss did not improve. Patience: 5/5\n",
      "Early stopping triggered after 14 epochs due to no improvement in validation loss.\n",
      "Training finished.\n",
      "Epoch 14/50 - Train Loss: 5.4110 - Val Loss: 8.1840\n",
      "Validation loss did not improve. Patience: 5/5\n",
      "Early stopping triggered after 14 epochs due to no improvement in validation loss.\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random # Import random for data splitting\n",
    "import numpy as np # Import numpy for potential random seed setting\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Assume all_word_phoneme_pairs and all_sentence_pairs are defined elsewhere\n",
    "# Example placeholders (replace with your actual data loading):\n",
    "# all_word_phoneme_pairs = [(\"hello\", \"H EH L OW\"), (\"world\", \"W ER L D\")]\n",
    "# all_sentence_pairs = [{\"text\": \"this is a test\", \"g2p\": \"DH IH S IH Z AH T EH S T\"}]\n",
    "\n",
    "# --- 1. Build Vocabularies ---\n",
    "\n",
    "def build_vocab(items, special_tokens=['<pad>', '<unk>', '<sos>', '<eos>']): # Added <sos> and <eos> for potential future seq2seq improvements\n",
    "    vocab = {tok: idx for idx, tok in enumerate(special_tokens)}\n",
    "    idx = len(vocab)\n",
    "    for item in items:\n",
    "        if item not in vocab:\n",
    "            vocab[item] = idx\n",
    "            idx += 1\n",
    "    return vocab\n",
    "\n",
    "# Gather all unique chars and phonemes from both datasets\n",
    "all_chars = set()\n",
    "all_phonemes = set()\n",
    "\n",
    "# --- Replace with your actual data loading and processing ---\n",
    "# Example using placeholder data structure:\n",
    "# for word, phonemes in all_word_phoneme_pairs:\n",
    "#     all_chars.update(list(word))\n",
    "#     all_phonemes.update(phonemes.split())\n",
    "\n",
    "# for pair in all_sentence_pairs:\n",
    "#     all_chars.update(list(pair['text']))\n",
    "#     all_phonemes.update(pair['g2p'].split())\n",
    "# --- End of placeholder example ---\n",
    "\n",
    "# Placeholder for demonstration - replace with your actual data loading\n",
    "# For this code to be runnable, we need some dummy data if the actual data isn't available\n",
    "try:\n",
    "    # Check if data variables exist (if loaded from elsewhere)\n",
    "    _ = all_word_phoneme_pairs\n",
    "    _ = all_sentence_pairs\n",
    "except NameError:\n",
    "    # Define dummy data if not found\n",
    "    print(\"Using dummy data for demonstration. Replace with your actual data loading.\")\n",
    "    all_word_phoneme_pairs = [(\"hello\", \"H EH L OW\"), (\"world\", \"W ER L D\"), (\"python\", \"P AY TH AA N\"),\n",
    "                              (\"example\", \"IH G Z AE M P AH L\"), (\"data\", \"D EY T AH\"), (\"science\", \"S AY AH N S\")]\n",
    "    all_sentence_pairs = [{\"text\": \"this is a test\", \"g2p\": \"DH IH S IH Z AH T EH S T\"},\n",
    "                          {\"text\": \"grapheme to phoneme\", \"g2p\": \"G R AE F IY M T UW F OW N IY M\"},\n",
    "                          {\"text\": \"neural network\", \"g2p\": \"N UW R AH L N EH T W ER K\"}]\n",
    "\n",
    "# Process dummy/actual data to build vocab\n",
    "for word, phonemes in all_word_phoneme_pairs:\n",
    "    all_chars.update(list(word))\n",
    "    all_phonemes.update(phonemes.split())\n",
    "\n",
    "for pair in all_sentence_pairs:\n",
    "    all_chars.update(list(pair['text']))\n",
    "    all_phonemes.update(pair['g2p'].split())\n",
    "\n",
    "\n",
    "char_vocab = build_vocab(sorted(list(all_chars))) # Convert set to list for sorting\n",
    "phoneme_vocab = build_vocab(sorted(list(all_phonemes))) # Convert set to list for sorting\n",
    "\n",
    "# --- 2. Dataset Classes ---\n",
    "\n",
    "class G2PDataset(Dataset):\n",
    "    def __init__(self, samples, char_vocab, phoneme_vocab):\n",
    "        self.samples = samples # Samples are passed directly now after splitting\n",
    "        self.char_vocab = char_vocab\n",
    "        self.phoneme_vocab = phoneme_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chars, phonemes = self.samples[idx]\n",
    "        # Use .get with a default to handle potential missing keys gracefully, though build_vocab should cover most.\n",
    "        char_ids = [self.char_vocab.get(c, self.char_vocab['<unk>']) for c in chars]\n",
    "        phoneme_ids = [self.phoneme_vocab.get(p, self.phoneme_vocab['<unk>']) for p in phonemes]\n",
    "        return torch.tensor(char_ids, dtype=torch.long), torch.tensor(phoneme_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    char_seqs, phoneme_seqs = zip(*batch)\n",
    "    char_lens = [len(seq) for seq in char_seqs]\n",
    "    phoneme_lens = [len(seq) for seq in phoneme_seqs]\n",
    "    max_char_len = max(char_lens)\n",
    "    max_phoneme_len = max(phoneme_lens)\n",
    "    pad_char = char_vocab['<pad>']\n",
    "    pad_phoneme = phoneme_vocab['<pad>']\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_chars = [torch.cat([seq, torch.full((max_char_len - len(seq),), pad_char, dtype=torch.long)]) for seq in char_seqs]\n",
    "    padded_phonemes = [torch.cat([seq, torch.full((max_phoneme_len - len(seq),), pad_phoneme, dtype=torch.long)]) for seq in phoneme_seqs]\n",
    "\n",
    "    return torch.stack(padded_chars), torch.stack(padded_phonemes), torch.tensor(char_lens), torch.tensor(phoneme_lens)\n",
    "\n",
    "# --- Data Splitting ---\n",
    "# Combine all samples first\n",
    "all_samples = []\n",
    "for word, phonemes in all_word_phoneme_pairs:\n",
    "    all_samples.append((list(word), phonemes.split()))\n",
    "for pair in all_sentence_pairs:\n",
    "    all_samples.append((list(pair['text']), pair['g2p'].split()))\n",
    "\n",
    "# Shuffle samples\n",
    "random.shuffle(all_samples)\n",
    "\n",
    "# Define split ratio\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(all_samples) * train_ratio)\n",
    "\n",
    "# Split data\n",
    "train_samples = all_samples[:train_size]\n",
    "val_samples = all_samples[train_size:]\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = G2PDataset(train_samples, char_vocab, phoneme_vocab)\n",
    "val_dataset = G2PDataset(val_samples, char_vocab, phoneme_vocab)\n",
    "\n",
    "\n",
    "# --- 4. Prepare DataLoaders ---\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn) # No need to shuffle validation data\n",
    "\n",
    "# --- 3. Model ---\n",
    "\n",
    "class SimpleLSTMG2P(nn.Module):\n",
    "    def __init__(self, char_vocab_size, phoneme_vocab_size, emb_dim=64, hidden_dim=128, dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(char_vocab_size, emb_dim, padding_idx=char_vocab['<pad>'])\n",
    "        # Dropout layer after embedding\n",
    "        self.dropout_emb = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Bidirectional LSTM encoder\n",
    "        # dropout argument in LSTM applies dropout to the output of each layer except the last layer\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True, dropout=dropout_prob)\n",
    "\n",
    "        # Unidirectional LSTM decoder\n",
    "        # Input to decoder is the final encoder hidden state (bidirectional -> 2 * hidden_dim)\n",
    "        self.decoder = nn.LSTM(hidden_dim * 2, hidden_dim, batch_first=True, dropout=dropout_prob)\n",
    "\n",
    "        # Linear layer to map decoder output to phoneme vocabulary size\n",
    "        self.fc = nn.Linear(hidden_dim, phoneme_vocab_size)\n",
    "        # Dropout layer before the final linear layer\n",
    "        self.dropout_fc = nn.Dropout(dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, char_seqs, char_lens, target_len):\n",
    "        # Apply embedding\n",
    "        emb = self.embedding(char_seqs)\n",
    "        # Apply dropout to embeddings\n",
    "        emb = self.dropout_emb(emb)\n",
    "\n",
    "        # Pack padded sequences for efficient LSTM processing\n",
    "        # char_lens must be on CPU for pack_padded_sequence\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, char_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # Pass through encoder\n",
    "        enc_out, (h, c) = self.encoder(packed)\n",
    "\n",
    "        # Pad packed sequence back to original length\n",
    "        enc_out, _ = nn.utils.rnn.pad_packed_sequence(enc_out, batch_first=True)\n",
    "\n",
    "        # Simple decoder input: Repeat the final hidden state of the encoder\n",
    "        # For bidirectional LSTM, the final hidden state (h) has shape (2 * num_layers, batch_size, hidden_dim)\n",
    "        # We take the hidden state from the last layer (h[-2:, :, :]) and concatenate the forward and backward parts.\n",
    "        # Then repeat it for each time step in the target sequence.\n",
    "        # Note: This is a very basic decoder input strategy. More advanced models use attention.\n",
    "        # h[-2, :, :] is the last layer's forward hidden state\n",
    "        # h[-1, :, :] is the last layer's backward hidden state\n",
    "        last_encoder_hidden = torch.cat((h[-2, :, :], h[-1, :, :]), dim=1) # Concatenate forward and backward last layer hidden states\n",
    "        dec_input = last_encoder_hidden.unsqueeze(1).repeat(1, target_len, 1) # Repeat for target_len times\n",
    "\n",
    "        # Pass through decoder\n",
    "        dec_out, _ = self.decoder(dec_input)\n",
    "\n",
    "        # Apply dropout before the final linear layer\n",
    "        dec_out = self.dropout_fc(dec_out)\n",
    "\n",
    "        # Pass through linear layer to get logits\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# --- 5. Example Training Loop with Early Stopping ---\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Pass dropout_prob to the model constructor\n",
    "model = SimpleLSTMG2P(len(char_vocab), len(phoneme_vocab), dropout_prob=0.3).to(device) # Added dropout_prob\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=phoneme_vocab['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50 # Set a higher number of epochs, early stopping will stop it\n",
    "patience = 5 # How many epochs to wait for improvement before stopping\n",
    "best_val_loss = float('inf') # Initialize best validation loss\n",
    "patience_counter = 0 # Counter for epochs without improvement\n",
    "\n",
    "print(f\"Starting training for up to {num_epochs} epochs with patience of {patience}...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train() # Set model to training mode (enables dropout)\n",
    "    total_train_loss = 0\n",
    "    for chars, phonemes, char_lens, phoneme_lens in train_dataloader:\n",
    "        chars, phonemes = chars.to(device), phonemes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure target_len is taken from the actual phoneme batch size for correct decoder input size\n",
    "        target_len = phonemes.size(1)\n",
    "        logits = model(chars, char_lens, target_len)\n",
    "\n",
    "        # Reshape logits and targets for CrossEntropyLoss\n",
    "        logits = logits.view(-1, logits.size(-1))\n",
    "        targets = phonemes.view(-1)\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval() # Set model to evaluation mode (disables dropout)\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad(): # Disable gradient calculation for validation\n",
    "        for chars, phonemes, char_lens, phoneme_lens in val_dataloader:\n",
    "            chars, phonemes = chars.to(device), phonemes.to(device)\n",
    "\n",
    "            target_len = phonemes.size(1)\n",
    "            logits = model(chars, char_lens, target_len)\n",
    "\n",
    "            logits = logits.view(-1, logits.size(-1))\n",
    "            targets = phonemes.view(-1)\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- Early Stopping Logic ---\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0 # Reset patience counter\n",
    "        # Optional: Save the model state dict that achieved the best validation loss\n",
    "        # torch.save(model.state_dict(), 'best_g2p_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1 # Increment patience counter\n",
    "        print(f\"Validation loss did not improve. Patience: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs due to no improvement in validation loss.\")\n",
    "            # Optional: Load the best model state dict before stopping\n",
    "            # model.load_state_dict(torch.load('best_g2p_model.pth'))\n",
    "            break # Stop training\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed9ada90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: عامل ايه يا علي؟ أنا كويس الحمد لله. كتابك الجديد فين؟\n",
      "Predicted phonemes: ʔeːh ʔeːh jaː ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh? ʔeːh?\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test sentence\n",
    "test_text = \"عامل ايه يا علي؟ أنا كويس الحمد لله. كتابك الجديد فين؟\"\n",
    "test_chars = [char_vocab.get(c, char_vocab['<unk>']) for c in test_text]\n",
    "test_tensor = torch.tensor([test_chars], dtype=torch.long).to(device)\n",
    "test_len = torch.tensor([len(test_chars)])\n",
    "\n",
    "# Set a reasonable output length (can be same as input or a bit longer)\n",
    "output_len = len(test_chars) + 5\n",
    "\n",
    "# Run the model in eval mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_tensor, test_len, output_len)\n",
    "    pred_ids = logits.argmax(-1).cpu().numpy()[0]\n",
    "\n",
    "# Convert predicted ids to phonemes\n",
    "id2phoneme = {v: k for k, v in phoneme_vocab.items()}\n",
    "pred_phonemes = [id2phoneme.get(i, '<unk>') for i in pred_ids]\n",
    "\n",
    "# Print the result\n",
    "print(\"Input:\", test_text)\n",
    "print(\"Predicted phonemes:\", \" \".join(pred_phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afda22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_pyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
